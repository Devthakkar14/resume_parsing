{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install importlib-metadata==3.2.0\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip install PyPDF2\n",
        "!pip install PyPDF2\n",
        "!pip install pdfminer.six\n",
        "!pip install PyMuPDF\n",
        "!pip install tika"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taZBmwiUxTr_",
        "outputId": "919d9f87-cced-44e1-cf06-9d982526eb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting importlib-metadata==3.2.0\n",
            "  Downloading importlib_metadata-3.2.0-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata==3.2.0) (3.15.0)\n",
            "Installing collected packages: importlib-metadata\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.1.0\n",
            "    Uninstalling importlib-metadata-6.1.0:\n",
            "      Successfully uninstalled importlib-metadata-6.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.4.3 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.2.0 which is incompatible.\n",
            "gym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 3.2.0 which is incompatible.\n",
            "flask 2.2.3 requires importlib-metadata>=3.6.0; python_version < \"3.10\", but you have importlib-metadata 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed importlib-metadata-3.2.0\n",
            "2023-04-06 14:07:43.498522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-06 14:07:44.945341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip\n",
            "\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not install requirement https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip because of HTTP error 404 Client Error: Not Found for url: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip for URL https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from PyPDF2) (4.5.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six) (40.0.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20221105\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.21.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.21.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tika) (67.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from tika) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->tika) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->tika) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->tika) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->tika) (3.4)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32641 sha256=13e0477671bb54ad6d7828dd7b2ac786168794c2998f34b72b433baa1872436a\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/56/18/e752060632d32c39c9c4545e756dad281f8504dafcfac02b95\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import spacy\n",
        "import json\n",
        "from tika import parser\n",
        "import fitz\n",
        "from operator import itemgetter\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "from spacy.matcher import Matcher"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPk816FdiUrK",
        "outputId": "1c4dbca1-d4b7-4772-d341-f9ae6a2f3f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r '/content/extracted_data'\n",
        "!rm -r '/content/text_resumes'\n",
        "!rm -r '/content/json_data'\n",
        "!rm -r '/content/headings'"
      ],
      "metadata": {
        "id": "41oNIADDiYC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b176977-78f1-4c90-cedf-4768de023aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/extracted_data': No such file or directory\n",
            "rm: cannot remove '/content/text_resumes': No such file or directory\n",
            "rm: cannot remove '/content/json_data': No such file or directory\n",
            "rm: cannot remove '/content/headings': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/text_resumes'\n",
        "!mkdir '/content/extracted_data'\n",
        "!mkdir '/content/json_data'\n",
        "!mkdir '/content/headings'"
      ],
      "metadata": {
        "id": "i47bpQ1NidRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResumeInformationExtractor:\n",
        "  def __init__(self, directory_path):\n",
        "    self.directory = directory_path\n",
        "    self.text_directory = '/content/text_resumes'\n",
        "    self.block_directory = '/content/extracted_data'\n",
        "    self.json_directory = '/content/json_data'\n",
        "    self.headings_directory = '/content/headings'\n",
        "    self.store_text()\n",
        "    print(\"DONE\")\n",
        "\n",
        "  def fonts(self, doc, granularity=False):\n",
        "    styles = {}\n",
        "    font_counts = {}\n",
        "    for page in doc:\n",
        "      blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "      for b in blocks:\n",
        "          if b['type'] == 0:\n",
        "              for l in b[\"lines\"]:\n",
        "                  for s in l[\"spans\"]:\n",
        "                      if granularity:\n",
        "                          identifier = \"{0}_{1}_{2}_{3}\".format(s['size'], s['flags'], s['font'], s['color'])\n",
        "                          styles[identifier] = {'size': s['size'], 'flags': s['flags'], 'font': s['font'],\n",
        "                                                'color': s['color']}\n",
        "                      else:\n",
        "                          identifier = \"{0}\".format(s['size'])\n",
        "                          styles[identifier] = {'size': s['size'], 'font': s['font']}\n",
        "\n",
        "                      font_counts[identifier] = font_counts.get(identifier, 0) + 1  # count the fonts usage\n",
        "\n",
        "    font_counts = sorted(font_counts.items(), key=itemgetter(1), reverse=True)\n",
        "\n",
        "    if len(font_counts) < 1:\n",
        "        raise ValueError(\"Zero discriminating fonts found!\")\n",
        "\n",
        "    return font_counts, styles\n",
        "\n",
        "  def font_tags(self, font_counts, styles):\n",
        "    p_style = styles[font_counts[0][0]]\n",
        "    p_size = p_style['size']\n",
        "    font_sizes = []\n",
        "    for (font_size, count) in font_counts:\n",
        "        font_sizes.append(float(font_size))\n",
        "    font_sizes.sort(reverse=True)\n",
        "    idx = 0\n",
        "    size_tag = {}\n",
        "    for size in font_sizes:\n",
        "        idx += 1\n",
        "        if size == p_size:\n",
        "            idx = 0\n",
        "            size_tag[size] = '<p>'\n",
        "        if size > p_size:\n",
        "            size_tag[size] = '<h{0}>'.format(idx)\n",
        "        elif size < p_size:\n",
        "            size_tag[size] = '<s{0}>'.format(idx)\n",
        "\n",
        "    return size_tag\n",
        "\n",
        "\n",
        "  def headers_para(self, doc, size_tag):\n",
        "    header_para = []\n",
        "    first = True\n",
        "    previous_s = {}\n",
        "\n",
        "    for page in doc:\n",
        "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "        for b in blocks:\n",
        "            if b['type'] == 0:\n",
        "                block_string = \"\"\n",
        "                for l in b[\"lines\"]:\n",
        "                    for s in l[\"spans\"]:\n",
        "                        if s['text'].strip():\n",
        "                            if first:\n",
        "                                previous_s = s\n",
        "                                first = False\n",
        "                                block_string = size_tag[s['size']] + s['text']\n",
        "                            else:\n",
        "                                if s['size'] == previous_s['size']:\n",
        "                                    if block_string and all((c == \"|\") for c in block_string):\n",
        "                                        block_string = size_tag[s['size']] + s['text']\n",
        "                                    if block_string == \"\":\n",
        "                                        block_string = size_tag[s['size']] + s['text']\n",
        "                                    else:\n",
        "                                        block_string += \" \" + s['text']\n",
        "                                else:\n",
        "                                    header_para.append(block_string)\n",
        "                                    block_string = size_tag[s['size']] + s['text']\n",
        "                                previous_s = s\n",
        "                    block_string += \"|\"\n",
        "                header_para.append(block_string)\n",
        "    return header_para\n",
        "\n",
        "\n",
        "\n",
        "  def get_headings(self, elements):\n",
        "    # resume_headings = ['Personal Information', 'Education', 'Academic Projects', 'Academic Achievements and Awards', 'Technical Skills', 'Work Experience', 'Projects', 'Certifications', 'Publications', 'Skills', 'Achievements and Awards', 'Volunteering', 'Extracurricular Activities', 'Leadership', 'Hobbies', 'References', 'Achievements', 'Experience']\n",
        "    headings_ = []\n",
        "    for item in elements:\n",
        "        if item.startswith(('<h1>', '<h2>')):\n",
        "            headings_.append(item)\n",
        "    headings = []\n",
        "    for item in headings_:\n",
        "        if '>' in item and len(item.split('>')) > 1:\n",
        "            text = item.split('>')[1].split('|')[0].strip()\n",
        "            headings.append(text)\n",
        "    filtered_words = []\n",
        "    for word in headings:\n",
        "      word = ''.join(e for e in word if e.isalnum() or e in ['/', '\\\\', ' '])\n",
        "      filtered_words.append(word)\n",
        "    # filtered_words = [word for word in headings if word.upper() in resume_headings]\n",
        "    return filtered_words\n",
        "\n",
        "\n",
        "\n",
        "  def extract_data(self, text , headings):\n",
        "    regex_patterns = {}\n",
        "    for heading in headings:\n",
        "        regex_patterns[heading] = re.compile(r'^' + heading, re.IGNORECASE)\n",
        "\n",
        "    text_blocks = {}\n",
        "    for heading in headings:\n",
        "        text_blocks[heading] = ''\n",
        "\n",
        "    current_heading = None\n",
        "    i = 0\n",
        "\n",
        "    for line in text.split('\\n'):\n",
        "        found_heading = False\n",
        "        for heading, regex_pattern in regex_patterns.items():\n",
        "            if regex_pattern.match(line):\n",
        "                current_heading = heading\n",
        "                found_heading = True\n",
        "                break\n",
        "        if found_heading:\n",
        "            continue\n",
        "\n",
        "        if current_heading is not None:\n",
        "            text_blocks[current_heading] += line + '\\n'\n",
        "    return text_blocks\n",
        "\n",
        "  def get_file_content(self, doc):\n",
        "    # parsed = parser.from_file(path)\n",
        "    # result = parsed['content']\n",
        "    # if not result:\n",
        "    #   return result\n",
        "    # else:\n",
        "    #   result = \"\\n\".join([line for line in result.split(\"\\n\") if line.strip() != \"\"])\n",
        "    header_para = []\n",
        "    first = True\n",
        "    previous_s = {}\n",
        "\n",
        "    for page in doc:\n",
        "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "        for b in blocks:\n",
        "            if b['type'] == 0:\n",
        "                block_string = \"\"\n",
        "                for l in b[\"lines\"]:\n",
        "                    for s in l[\"spans\"]:\n",
        "                        if s['text'].strip():\n",
        "                            if first:\n",
        "                                previous_s = s\n",
        "                                first = False\n",
        "                                block_string = s['text']\n",
        "                            else:\n",
        "                                if s['size'] == previous_s['size']:\n",
        "                                    if block_string and all((c == \"|\") for c in block_string):\n",
        "                                        block_string = s['text']\n",
        "                                    if block_string == \"\":\n",
        "                                        block_string = s['text']\n",
        "                                    else:\n",
        "                                        block_string += \" \" + s['text']\n",
        "                                else:\n",
        "                                    header_para.append(block_string)\n",
        "                                    block_string = s['text']\n",
        "                                previous_s = s\n",
        "                header_para.append(block_string)\n",
        "    result = '\\n'.join(header_para)\n",
        "    return result\n",
        "\n",
        "  def store_text(self):\n",
        "    print(self.directory)\n",
        "    files = sorted(os.listdir(self.directory))\n",
        "\n",
        "    for file in files:\n",
        "        path = self.directory + '/' + file\n",
        "        doc = fitz.open(path)\n",
        "        text_data = self.get_file_content(doc)\n",
        "        if not text_data:\n",
        "          continue\n",
        "        with open(self.text_directory + '/' + file.split('.')[0] + '.txt', 'w') as f:\n",
        "            f.write(text_data)\n",
        "\n",
        "        font_counts, styles = self.fonts(doc, granularity=False)\n",
        "        size_tag = self.font_tags(font_counts, styles)\n",
        "        elements = self.headers_para(doc, size_tag)\n",
        "        headings = self.get_headings(elements)\n",
        "        with open(self.headings_directory + '/' + file.split('.')[0] + '.txt', 'w') as f:\n",
        "          f.write(str(headings))\n",
        "\n",
        "        text_blocks = self.extract_data(text_data , headings)\n",
        "        with open(self.block_directory + '/' + file.split('.')[0] + '.txt', 'w') as f:\n",
        "            for heading, text_block in text_blocks.items():\n",
        "                if text_block:\n",
        "                    f.write(heading.upper() + '\\n')\n",
        "                    f.write(text_block + '-' * 50 + '\\n')\n",
        "\n",
        "        with open(self.json_directory + '/' + file.split('.')[0] + '.json', 'w') as f:\n",
        "            non_empty_text_blocks = {key: value.replace('\\n', ' ') for key, value in text_blocks.items() if value}\n",
        "            json.dump(non_empty_text_blocks, f, indent=2)\n",
        "    return\n"
      ],
      "metadata": {
        "id": "pm_728WRiiVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESUME_DIRECTORY = '/content/type6'\n",
        "ResumeInformationExtractor(RESUME_DIRECTORY)\n",
        "!zip -r /content/json_data6.zip /content/json_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn9OyHQbjWey",
        "outputId": "2ea9ef75-e2bc-46e5-e673-476fcc764907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/type6\n",
            "DONE\n",
            "updating: content/json_data/ (stored 0%)\n",
            "updating: content/json_data/pdf_resume_940.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_903.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_708.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_274.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_507.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_1002.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_263.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_156.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_466.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_301.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_533.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_551.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_41.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_636.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_994.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_924.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_749.json (deflated 35%)\n",
            "updating: content/json_data/pdf_resume_375.json (deflated 36%)\n",
            "updating: content/json_data/pdf_resume_268.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_302.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_336.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_439.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_815.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_72.json (deflated 34%)\n",
            "updating: content/json_data/pdf_resume_757.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_553.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_776.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_850.json (deflated 34%)\n",
            "updating: content/json_data/pdf_resume_840.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_355.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_696.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_852.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_415.json (deflated 34%)\n",
            "updating: content/json_data/pdf_resume_592.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_837.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_458.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_243.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_847.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_516.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_913.json (deflated 32%)\n",
            "updating: content/json_data/pdf_resume_641.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_512.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_721.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_11.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_18.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_612.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_207.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_477.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_755.json (deflated 31%)\n",
            "updating: content/json_data/pdf_resume_232.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_681.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_996.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_584.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_660.json (deflated 36%)\n",
            "updating: content/json_data/pdf_resume_883.json (deflated 55%)\n",
            "updating: content/json_data/pdf_resume_558.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_995.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_78.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_785.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_904.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_86.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_253.json (deflated 33%)\n",
            "updating: content/json_data/pdf_resume_457.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_189.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_178.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_574.json (deflated 55%)\n",
            "updating: content/json_data/pdf_resume_51.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_479.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_939.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_275.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_901.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_647.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_205.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_1003.json (deflated 54%)\n",
            "updating: content/json_data/pdf_resume_875.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_585.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_3.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_839.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_603.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_334.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_181.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_139.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_305.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_43.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_862.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_966.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_91.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_712.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_19.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_746.json (deflated 15%)\n",
            "updating: content/json_data/pdf_resume_822.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_17.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_47.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_771.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_893.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_21.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_287.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_752.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_554.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_409.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_1015.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_357.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_951.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_937.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_133.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_404.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_74.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_566.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_431.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_327.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_687.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_265.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_874.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_20.json (deflated 11%)\n",
            "updating: content/json_data/pdf_resume_859.json (deflated 30%)\n",
            "updating: content/json_data/pdf_resume_173.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_308.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_157.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_390.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_476.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_998.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_947.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_1028.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_756.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_818.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_6.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_583.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_379.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_94.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_269.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_26.json (deflated 28%)\n",
            "updating: content/json_data/pdf_resume_407.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_549.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_702.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_506.json (deflated 36%)\n",
            "updating: content/json_data/pdf_resume_494.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_634.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_933.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_935.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_1024.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_567.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_194.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_651.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_81.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_411.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_701.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_1019.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_975.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_540.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_273.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_344.json (deflated 28%)\n",
            "updating: content/json_data/pdf_resume_780.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_736.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_498.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_372.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_130.json (deflated 28%)\n",
            "updating: content/json_data/pdf_resume_671.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_256.json (deflated 63%)\n",
            "updating: content/json_data/pdf_resume_538.json (deflated 55%)\n",
            "updating: content/json_data/pdf_resume_790.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_138.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_23.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_229.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_208.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_515.json (deflated 54%)\n",
            "updating: content/json_data/pdf_resume_16.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_290.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_700.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_581.json (deflated 34%)\n",
            "updating: content/json_data/pdf_resume_223.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_902.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_787.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_188.json (deflated 35%)\n",
            "updating: content/json_data/pdf_resume_39.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_248.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_914.json (deflated 33%)\n",
            "updating: content/json_data/pdf_resume_851.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_174.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_68.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_950.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_552.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_802.json (deflated 29%)\n",
            "updating: content/json_data/pdf_resume_396.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_297.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_76.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_1026.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_377.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_777.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_307.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_170.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_48.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_982.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_991.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_1001.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_604.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_128.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_198.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_14.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_522.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_470.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_931.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_519.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_635.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_1009.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_841.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_788.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_910.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_525.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_313.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_436.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_395.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_361.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_918.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_246.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_332.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_421.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_158.json (deflated 24%)\n",
            "updating: content/json_data/pdf_resume_83.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_1007.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_446.json (deflated 54%)\n",
            "updating: content/json_data/pdf_resume_199.json (deflated 20%)\n",
            "updating: content/json_data/pdf_resume_92.json (deflated 33%)\n",
            "updating: content/json_data/pdf_resume_440.json (deflated 17%)\n",
            "updating: content/json_data/pdf_resume_848.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_224.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_271.json (deflated 21%)\n",
            "updating: content/json_data/pdf_resume_267.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_32.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_254.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_53.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_543.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_825.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_944.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_195.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_49.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_820.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_40.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_961.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_113.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_865.json (deflated 42%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.removedirs('/content/type6/.ipynb_checkpoints')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "IoMLhlhd52_G",
        "outputId": "7af267f0-286e-4a76-d36f-5225d6772a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-315361464fdb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/type6/.ipynb_checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.9/os.py\u001b[0m in \u001b[0;36mremovedirs\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \"\"\"\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/type6/.ipynb_checkpoints'"
          ]
        }
      ]
    }
  ]
}