{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FpSa3OEg4wQ",
        "outputId": "3aee8aa0-5cdc-4b2c-f29d-4838956108db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting importlib-metadata==3.2.0\n",
            "  Downloading importlib_metadata-3.2.0-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata==3.2.0) (3.15.0)\n",
            "Installing collected packages: importlib-metadata\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.1.0\n",
            "    Uninstalling importlib-metadata-6.1.0:\n",
            "      Successfully uninstalled importlib-metadata-6.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.4.3 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.2.0 which is incompatible.\n",
            "gym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 3.2.0 which is incompatible.\n",
            "flask 2.2.3 requires importlib-metadata>=3.6.0; python_version < \"3.10\", but you have importlib-metadata 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed importlib-metadata-3.2.0\n",
            "2023-04-06 13:18:49.353422: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-06 13:18:50.549888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip\n",
            "\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not install requirement https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip because of HTTP error 404 Client Error: Not Found for url: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip for URL https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from PyPDF2) (4.5.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six) (40.0.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20221105\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.21.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.21.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tika) (67.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from tika) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->tika) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->tika) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->tika) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->tika) (2022.12.7)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32641 sha256=c572e8be354c119a8fdaf3acee2ebb0aed6ec9e5e7fdd2bd4c82e28b979ffccf\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/56/18/e752060632d32c39c9c4545e756dad281f8504dafcfac02b95\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-2.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install importlib-metadata==3.2.0\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz!pip install PyPDF2\n",
        "!pip install PyPDF2\n",
        "!pip install pdfminer.six\n",
        "!pip install PyMuPDF\n",
        "!pip install tika"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knd50UBzgpYl",
        "outputId": "4d6124e8-90d1-44b2-ce64-a6e072821fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import spacy\n",
        "import json\n",
        "from tika import parser\n",
        "import fitz\n",
        "from operator import itemgetter\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "from spacy.matcher import Matcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs32uFHNFXHh"
      },
      "outputs": [],
      "source": [
        "!rm -r '/content/extracted_data'\n",
        "!rm -r '/content/text_resumes'\n",
        "!rm -r '/content/json_data'\n",
        "!rm -r '/content/headings'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEbk_BNRFYfj"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/text_resumes'\n",
        "!mkdir '/content/extracted_data'\n",
        "!mkdir '/content/json_data'\n",
        "!mkdir '/content/headings'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwr-c0SJFZPR"
      },
      "outputs": [],
      "source": [
        "class ResumeInformationExtractor:\n",
        "  def __init__(self, directory_path):\n",
        "    self.directory = directory_path\n",
        "    self.text_directory = '/content/text_resumes'\n",
        "    self.block_directory = '/content/extracted_data'\n",
        "    self.json_directory = '/content/json_data'\n",
        "    self.headings_directory = '/content/headings'\n",
        "    self.store_text()\n",
        "    print(\"DONE\")\n",
        "\n",
        "  def fonts(self, doc, granularity=False):\n",
        "    styles = {}\n",
        "    font_counts = {}\n",
        "    for page in doc:\n",
        "      blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "      for b in blocks:\n",
        "          if b['type'] == 0:\n",
        "              for l in b[\"lines\"]:\n",
        "                  for s in l[\"spans\"]:\n",
        "                      if granularity:\n",
        "                          identifier = \"{0}_{1}_{2}_{3}\".format(s['size'], s['flags'], s['font'], s['color'])\n",
        "                          styles[identifier] = {'size': s['size'], 'flags': s['flags'], 'font': s['font'],\n",
        "                                                'color': s['color']}\n",
        "                      else:\n",
        "                          identifier = \"{0}\".format(s['size'])\n",
        "                          styles[identifier] = {'size': s['size'], 'font': s['font']}\n",
        "\n",
        "                      font_counts[identifier] = font_counts.get(identifier, 0) + 1  # count the fonts usage\n",
        "\n",
        "    font_counts = sorted(font_counts.items(), key=itemgetter(1), reverse=True)\n",
        "\n",
        "    if len(font_counts) < 1:\n",
        "        raise ValueError(\"Zero discriminating fonts found!\")\n",
        "\n",
        "    return font_counts, styles\n",
        "\n",
        "  def font_tags(self, font_counts, styles):\n",
        "    p_style = styles[font_counts[0][0]]\n",
        "    p_size = p_style['size']\n",
        "    font_sizes = []\n",
        "    for (font_size, count) in font_counts:\n",
        "        font_sizes.append(float(font_size))\n",
        "    font_sizes.sort(reverse=True)\n",
        "    idx = 0\n",
        "    size_tag = {}\n",
        "    for size in font_sizes:\n",
        "        idx += 1\n",
        "        if size == p_size:\n",
        "            idx = 0\n",
        "            size_tag[size] = '<p>'\n",
        "        if size > p_size:\n",
        "            size_tag[size] = '<h{0}>'.format(idx)\n",
        "        elif size < p_size:\n",
        "            size_tag[size] = '<s{0}>'.format(idx)\n",
        "\n",
        "    return size_tag\n",
        "\n",
        "\n",
        "  def headers_para(self, doc, size_tag):\n",
        "    header_para = []\n",
        "    first = True\n",
        "    previous_s = {}\n",
        "\n",
        "    for page in doc:\n",
        "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "        for b in blocks:\n",
        "            if b['type'] == 0:\n",
        "                block_string = \"\"\n",
        "                for l in b[\"lines\"]:\n",
        "                    for s in l[\"spans\"]:\n",
        "                        if s['text'].strip():\n",
        "                            if first:\n",
        "                                previous_s = s\n",
        "                                first = False\n",
        "                                block_string = size_tag[s['size']] + s['text']\n",
        "                            else:\n",
        "                                if s['size'] == previous_s['size']:\n",
        "                                    if block_string and all((c == \"|\") for c in block_string):\n",
        "                                        block_string = size_tag[s['size']] + s['text']\n",
        "                                    if block_string == \"\":\n",
        "                                        block_string = size_tag[s['size']] + s['text']\n",
        "                                    else:\n",
        "                                        block_string += \" \" + s['text']\n",
        "                                else:\n",
        "                                    header_para.append(block_string)\n",
        "                                    block_string = size_tag[s['size']] + s['text']\n",
        "                                previous_s = s\n",
        "                    block_string += \"|\"\n",
        "                header_para.append(block_string)\n",
        "    return header_para\n",
        "\n",
        "\n",
        "\n",
        "  def get_headings(self, elements):\n",
        "    # resume_headings = ['Personal Information', 'Education', 'Academic Projects', 'Academic Achievements and Awards', 'Technical Skills', 'Work Experience', 'Projects', 'Certifications', 'Publications', 'Skills', 'Achievements and Awards', 'Volunteering', 'Extracurricular Activities', 'Leadership', 'Hobbies', 'References', 'Achievements', 'Experience']\n",
        "    headings_ = []\n",
        "    for item in elements:\n",
        "        if item.startswith(('<h1>', '<h2>')):\n",
        "            headings_.append(item)\n",
        "    headings = []\n",
        "    for item in headings_:\n",
        "        if '>' in item and len(item.split('>')) > 1:\n",
        "            text = item.split('>')[1].split('|')[0].strip()\n",
        "            headings.append(text)\n",
        "    filtered_words = []\n",
        "    for word in headings:\n",
        "      word = ''.join(e for e in word if e.isalnum() or e in ['/', '\\\\', ' '])\n",
        "      filtered_words.append(word)\n",
        "    # filtered_words = [word for word in headings if word.upper() in resume_headings]\n",
        "    return filtered_words\n",
        "\n",
        "\n",
        "\n",
        "  def extract_data(self, text , headings):\n",
        "    regex_patterns = {}\n",
        "    for heading in headings:\n",
        "        regex_patterns[heading] = re.compile(r'^' + heading, re.IGNORECASE)\n",
        "\n",
        "    text_blocks = {}\n",
        "    for heading in headings:\n",
        "        text_blocks[heading] = ''\n",
        "\n",
        "    current_heading = None\n",
        "    i = 0\n",
        "\n",
        "    for line in text.split('\\n'):\n",
        "        found_heading = False\n",
        "        for heading, regex_pattern in regex_patterns.items():\n",
        "            if regex_pattern.match(line):\n",
        "                current_heading = heading\n",
        "                found_heading = True\n",
        "                break\n",
        "        if found_heading:\n",
        "            continue\n",
        "\n",
        "        if current_heading is not None:\n",
        "            text_blocks[current_heading] += line + '\\n'\n",
        "    return text_blocks\n",
        "\n",
        "  def get_file_content(self, doc):\n",
        "    # parsed = parser.from_file(path)\n",
        "    # result = parsed['content']\n",
        "    # if not result:\n",
        "    #   return result\n",
        "    # else:\n",
        "    #   result = \"\\n\".join([line for line in result.split(\"\\n\") if line.strip() != \"\"])\n",
        "    header_para = []\n",
        "    first = True\n",
        "    previous_s = {}\n",
        "\n",
        "    for page in doc:\n",
        "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
        "        for b in blocks:\n",
        "            if b['type'] == 0:\n",
        "                block_string = \"\"\n",
        "                for l in b[\"lines\"]:\n",
        "                    for s in l[\"spans\"]:\n",
        "                        if s['text'].strip():\n",
        "                            if first:\n",
        "                                previous_s = s\n",
        "                                first = False\n",
        "                                block_string = s['text']\n",
        "                            else:\n",
        "                                if s['size'] == previous_s['size']:\n",
        "                                    if block_string and all((c == \"|\") for c in block_string):\n",
        "                                        block_string = s['text']\n",
        "                                    if block_string == \"\":\n",
        "                                        block_string = s['text']\n",
        "                                    else:\n",
        "                                        block_string += \" \" + s['text']\n",
        "                                else:\n",
        "                                    header_para.append(block_string)\n",
        "                                    block_string = s['text']\n",
        "                                previous_s = s\n",
        "                header_para.append(block_string)\n",
        "    result = '\\n'.join(header_para)\n",
        "    return result\n",
        "\n",
        "  def store_text(self):\n",
        "    print(self.directory)\n",
        "    files = sorted(os.listdir(self.directory))\n",
        "\n",
        "    for file in files:\n",
        "        path = self.directory + '/' + file\n",
        "        doc = fitz.open(path)\n",
        "        text_data = self.get_file_content(doc)\n",
        "        if not text_data:\n",
        "          continue\n",
        "        with open(self.text_directory + '/' + file.split('.')[0] + '.txt', 'w') as f:\n",
        "            f.write(text_data)\n",
        "\n",
        "        font_counts, styles = self.fonts(doc, granularity=False)\n",
        "        size_tag = self.font_tags(font_counts, styles)\n",
        "        elements = self.headers_para(doc, size_tag)\n",
        "        headings = self.get_headings(elements)\n",
        "        with open(self.headings_directory + '/' + file.split('.')[0] + '.txt', 'w') as f:\n",
        "          f.write(str(headings))\n",
        "\n",
        "        text_blocks = self.extract_data(text_data , headings)\n",
        "        with open(self.block_directory + '/' + file.split('.')[0] + '.txt', 'w') as f:\n",
        "            for heading, text_block in text_blocks.items():\n",
        "                if text_block:\n",
        "                    f.write(heading.upper() + '\\n')\n",
        "                    f.write(text_block + '-' * 50 + '\\n')\n",
        "\n",
        "        with open(self.json_directory + '/' + file.split('.')[0] + '.json', 'w') as f:\n",
        "            non_empty_text_blocks = {key: value.replace('\\n', ' ') for key, value in text_blocks.items() if value}\n",
        "            json.dump(non_empty_text_blocks, f, indent=2)\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9azsvClMFaeI",
        "outputId": "56a0adcb-90aa-4a49-e4d9-438952eddff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/type2\n",
            "DONE\n",
            "updating: content/json_data/ (stored 0%)\n",
            "updating: content/json_data/pdf_resume_121.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_737.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_131.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_437.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_387.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_166.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_734.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_33.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_453.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_564.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_957.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_643.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_895.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_626.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_217.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_772.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_107.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_364.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_9.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_783.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_319.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_63.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_462.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_976.json (deflated 54%)\n",
            "updating: content/json_data/pdf_resume_461.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_293.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_175.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_503.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_385.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_761.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_1013.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_465.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_209.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_226.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_343.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_177.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_704.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_430.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_663.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_234.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_489.json (deflated 29%)\n",
            "updating: content/json_data/pdf_resume_455.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_478.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_912.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_719.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_143.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_160.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_908.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_812.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_441.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_579.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_808.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_813.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_652.json (deflated 66%)\n",
            "updating: content/json_data/pdf_resume_109.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_814.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_796.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_871.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_744.json (deflated 54%)\n",
            "updating: content/json_data/pdf_resume_159.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_117.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_713.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_992.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_244.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_845.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_952.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_342.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_689.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_1011.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_1014.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_89.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_1006.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_691.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_594.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_8.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_962.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_819.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_978.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_164.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_928.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_282.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_84.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_184.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_797.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_459.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_429.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_425.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_475.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_920.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_61.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_984.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_127.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_120.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_677.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_289.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_450.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_31.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_881.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_1031.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_835.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_619.json (deflated 34%)\n",
            "updating: content/json_data/pdf_resume_563.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_838.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_997.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_557.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_786.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_545.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_386.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_1000.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_400.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_659.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_692.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_899.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_948.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_892.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_371.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_150.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_898.json (deflated 56%)\n",
            "updating: content/json_data/pdf_resume_760.json (deflated 18%)\n",
            "updating: content/json_data/pdf_resume_534.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_13.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_283.json (deflated 35%)\n",
            "updating: content/json_data/pdf_resume_402.json (deflated 55%)\n",
            "updating: content/json_data/pdf_resume_281.json (deflated 30%)\n",
            "updating: content/json_data/pdf_resume_1012.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_509.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_55.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_291.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_705.json (deflated 37%)\n",
            "updating: content/json_data/pdf_resume_538.json (deflated 55%)\n",
            "updating: content/json_data/pdf_resume_499.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_680.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_632.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_300.json (deflated 54%)\n",
            "updating: content/json_data/pdf_resume_250.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_831.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_88.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_536.json (deflated 40%)\n",
            "updating: content/json_data/pdf_resume_999.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_834.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_162.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_29.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_151.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_766.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_396.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_657.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_829.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_62.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_71.json (deflated 48%)\n",
            "updating: content/json_data/pdf_resume_79.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_406.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_45.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_854.json (deflated 60%)\n",
            "updating: content/json_data/pdf_resume_312.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_789.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_329.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_48.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_510.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_830.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_982.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_625.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_773.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_500.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_34.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_672.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_805.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_349.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_146.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_872.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_280.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_905.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_735.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_219.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_186.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_384.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_73.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_759.json (deflated 45%)\n",
            "updating: content/json_data/pdf_resume_593.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_876.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_314.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_561.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_420.json (deflated 57%)\n",
            "updating: content/json_data/pdf_resume_279.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_493.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_679.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_46.json (deflated 38%)\n",
            "updating: content/json_data/pdf_resume_809.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_221.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_596.json (deflated 36%)\n",
            "updating: content/json_data/pdf_resume_985.json (deflated 56%)\n",
            "updating: content/json_data/pdf_resume_782.json (deflated 49%)\n",
            "updating: content/json_data/pdf_resume_57.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_261.json (deflated 53%)\n",
            "updating: content/json_data/pdf_resume_860.json (deflated 43%)\n",
            "updating: content/json_data/pdf_resume_98.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_764.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_690.json (deflated 50%)\n",
            "updating: content/json_data/pdf_resume_152.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_424.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_195.json (deflated 46%)\n",
            "updating: content/json_data/pdf_resume_296.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_266.json (deflated 47%)\n",
            "updating: content/json_data/pdf_resume_861.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_765.json (deflated 42%)\n",
            "updating: content/json_data/pdf_resume_770.json (deflated 51%)\n",
            "updating: content/json_data/pdf_resume_405.json (stored 0%)\n",
            "updating: content/json_data/pdf_resume_565.json (deflated 44%)\n",
            "updating: content/json_data/pdf_resume_412.json (deflated 39%)\n",
            "updating: content/json_data/pdf_resume_272.json (deflated 52%)\n",
            "updating: content/json_data/pdf_resume_352.json (deflated 41%)\n",
            "updating: content/json_data/pdf_resume_505.json (deflated 11%)\n"
          ]
        }
      ],
      "source": [
        "RESUME_DIRECTORY = '/content/type2'\n",
        "ResumeInformationExtractor(RESUME_DIRECTORY)\n",
        "!zip -r /content/json_data2.zip /content/json_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.removedirs('/content/type2/.ipynb_checkpoints')"
      ],
      "metadata": {
        "id": "FYz2DzQbuJZX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}